{"methods":["post"],"schemes":["http","https"],"security":[{"AK":[]}],"operationType":"read","deprecated":false,"systemTags":{"operationType":"none"},"parameters":[{"name":"ImageURL","in":"formData","schema":{"description":"图像URL地址。推荐使用上海地域的OSS链接，对于文件在本地或者非上海地域OSS链接的情况，请参见[文件URL处理](~~155645~~)。","type":"string","required":true,"example":"http://viapi-test.oss-cn-shanghai.aliyuncs.com/viapi-3.0domepic/facebody/DetectFace/DetectFace1.png","isFileTransferUrl":true}},{"name":"Landmark","in":"formData","schema":{"description":"是否需要返回人脸的特征点定位，取值true或false。","type":"boolean","required":false,"example":"true"}},{"name":"Quality","in":"formData","schema":{"description":"是否需要返回人脸质量，取值true或false。","type":"boolean","required":false,"example":"true"}},{"name":"Pose","in":"formData","schema":{"description":"是否需要返回人脸的姿态，取值true或false。","type":"boolean","required":false,"example":"true"}},{"name":"MaxFaceNumber","in":"formData","schema":{"description":"设置图片中人脸的最大返回数量，取值范围1~30。若想返回多个人脸检测结果，请正确设置。默认按返回参数FaceProbabilityList进行降序排列。","type":"integer","format":"int64","required":false,"maximum":"40","minimum":"1","example":"1"}}],"responses":{"200":{"schema":{"description":"1","type":"object","properties":{"RequestId":{"description":"请求ID。","type":"string","example":"26B5334B-FD8A-5994-A1DA-3CA8F7B25676"},"Data":{"description":"返回的结果数据内容。","type":"object","properties":{"FaceProbabilityList":{"description":"1","type":"array","items":{"description":"截图中包含人脸的概率，取值范围0~1。如有多个人脸，则依次返回。例如有两个人脸则返回`[face_prob1, face_prob2]`。图像中人脸区域分辨率越大，人脸越清晰，人脸正视，对应的该值越大。","type":"number","format":"float","example":"0.96"}},"Pupils":{"description":"1","type":"array","items":{"description":"左右两个瞳孔的中心点坐标和半径，每个人脸6个浮点数，顺序为`[left_iris_cenpt.x, left_iris_cenpt.y, left_iris_radius, right_iris_cenpt.x, right_iris_cenpt.y, right_iris_radis]`。","type":"number","format":"double","example":"[417.83, 226.09, 8.15, 517.46, 231.53, 8.15]"}},"FaceRectangles":{"description":"1","type":"array","items":{"description":"返回人脸矩形框，分别是`[left, top, width, height]`。如有多个人脸，则依次顺延，返回矩形框。例如有两个人脸则返回`[left1, top1, width1, height1, left2, top2, width2, height2]`。\nleft-top: 表示以图片左上角为坐标原点，目标框所对应的左上角点位置（x,y），表示框的第一个点距离图片左边界x像素，距离上边界y个像素。\nwidth-height：表示目标框的宽和高。\n目标框面积为width*height，目标框右下角坐标为（left+width,top+height）。","type":"integer","format":"int32","example":"[358, 141, 207, 255]"}},"FaceCount":{"description":"检测出的人脸个数。","type":"integer","format":"int32","example":"1"},"PoseList":{"description":"1","type":"array","items":{"description":"返回人脸姿态角度，格式为`[yaw, pitch, roll]`。如有多个人脸，则依次顺延。\n\n- yaw为左右角度，取值范围-90~90。\n\n- pitch为上下角度，取值范围-90~90。\n\n- roll为平面旋转角度，取值范围-180~180。","type":"number","format":"float","example":"[5.02, -3.95, 2.41]"}},"Landmarks":{"description":"1","type":"array","items":{"description":"人脸特征点定位结果，每个人脸返回一组特征点位置，表示方式为`（x0, y0, x1, y1, ……）`；如有多个人脸，则依次顺延，返回定位浮点数。","type":"number","format":"float","example":"[381.1, 201.72, 448.09, 205.17, 415.19, 191.2, 415.28, 201.64, 391.35, 196.03, 403.15, 191.57, 426.94, 194.07, 438.42, 197.65, ......]"}},"LandmarkScore":{"type":"array","items":{"description":"关键点检测综合分值，取值范围(0, 100]，推荐采用85的阈值（您可以按实际应用场景判断设置阈值与否及相应阈值大小），该分值越大，对应脸的关键点的质量越好，越有利于识别，可用来筛选人脸样本。","type":"number","format":"float","example":"95.89"}},"LandmarkCount":{"description":"人脸特征点数目，目前固定为105点。依次为：眉毛24点，眼睛32点，鼻子6点，嘴巴34点，外轮廓9点。","type":"integer","format":"int32","example":"105"},"Qualities":{"description":"人脸质量情况，分数越高表示越有利于识别。","type":"object","properties":{"ScoreList":{"description":"1","type":"array","items":{"description":"质量综合分数，分数越高越有利于识别，取值范围\\(0,100]。如有多张人脸，则依次返回。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表图片综合质量越高，小于85代表图片综合质量越低。","type":"number","format":"float","example":"99.92"}},"BlurList":{"description":"1","type":"array","items":{"description":"人脸模糊度对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表图片模糊的概率越低，小于85代表图片模糊的概率越高。","type":"number","format":"float","example":"99.21"}},"FnfList":{"description":"1","type":"array","items":{"description":"目标是否为人脸及其对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表图片是人脸的概率越高，小于85代表图片是人脸的概率越低。","type":"number","format":"float","example":"100"}},"GlassList":{"description":"1","type":"array","items":{"description":"眼镜等上半脸遮挡对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表戴眼镜的概率越低，小于85代表戴眼镜的概率越高。","type":"number","format":"float","example":"100"}},"IlluList":{"description":"1","type":"array","items":{"description":"光照对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表图片光照好的概率越高，小于85代表图片光照好的概率越低。","type":"number","format":"float","example":"100"}},"MaskList":{"description":"1","type":"array","items":{"description":"口罩等下半脸遮挡对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表戴口罩概率越低，小于85代表戴口罩概率越高。","type":"number","format":"float","example":"99.53"}},"NoiseList":{"description":"1","type":"array","items":{"description":"图片噪声对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表图片有噪声的概率越低，小于85代表图片有噪声的概率越高。","type":"number","format":"float","example":"99.74"}},"PoseList":{"description":"1","type":"array","items":{"description":"姿态对识别的影响分数，分数越高越有利于识别，取值范围\\(0,100]。如有多个人脸，则依次顺延。在识别时，推荐设置阈值大于等于85（您可以按实际应用场景判断设置阈值与否及相应阈值大小），大于85代表人脸姿态正面的概率越高，小于85代表人脸姿态正面的概率越低。","type":"number","format":"float","example":"100"}}}}}}}}}},"errorCodes":{"400":[{"errorCode":"ParameterError","errorMessage":"The parameter is invalid. Please check again."}],"403":[{"errorCode":"AuthFailed","errorMessage":"An error occurred while performing authorization. Please check your RAM configuration."}],"408":[{"errorCode":"Timeout","errorMessage":"The request has timed out."}],"503":[{"errorCode":"ServiceUnavailable","errorMessage":"The service is unavailable."}]},"responseDemo":"[{\"type\":\"json\",\"example\":\"{\\n  \\\"RequestId\\\": \\\"26B5334B-FD8A-5994-A1DA-3CA8F7B25676\\\",\\n  \\\"Data\\\": {\\n    \\\"FaceProbabilityList\\\": [\\n      0.96\\n    ],\\n    \\\"Pupils\\\": [\\n      0\\n    ],\\n    \\\"FaceRectangles\\\": [\\n      0\\n    ],\\n    \\\"FaceCount\\\": 1,\\n    \\\"PoseList\\\": [\\n      0\\n    ],\\n    \\\"Landmarks\\\": [\\n      0\\n    ],\\n    \\\"LandmarkScore\\\": [\\n      95.89\\n    ],\\n    \\\"LandmarkCount\\\": 105,\\n    \\\"Qualities\\\": {\\n      \\\"ScoreList\\\": [\\n        99.92\\n      ],\\n      \\\"BlurList\\\": [\\n        99.21\\n      ],\\n      \\\"FnfList\\\": [\\n        100\\n      ],\\n      \\\"GlassList\\\": [\\n        100\\n      ],\\n      \\\"IlluList\\\": [\\n        100\\n      ],\\n      \\\"MaskList\\\": [\\n        99.53\\n      ],\\n      \\\"NoiseList\\\": [\\n        99.74\\n      ],\\n      \\\"PoseList\\\": [\\n        100\\n      ]\\n    }\\n  }\\n}\",\"errorExample\":\"\"},{\"type\":\"xml\",\"example\":\"<DetectFaceResponse>\\n    <RequestId>26B5334B-FD8A-5994-A1DA-3CA8F7B25676</RequestId>\\n    <Data>\\n        <FaceProbabilityList>0.96</FaceProbabilityList>\\n        <Pupils>417.83</Pupils>\\n        <Pupils>226.09</Pupils>\\n        <Pupils>8.15</Pupils>\\n        <Pupils>517.46</Pupils>\\n        <Pupils>231.53</Pupils>\\n        <Pupils>8.15</Pupils>\\n        <FaceRectangles>358</FaceRectangles>\\n        <FaceRectangles>141</FaceRectangles>\\n        <FaceRectangles>207</FaceRectangles>\\n        <FaceRectangles>255</FaceRectangles>\\n        <FaceCount>1</FaceCount>\\n        <PoseList>5.02</PoseList>\\n        <PoseList>-3.95</PoseList>\\n        <PoseList>2.41</PoseList>\\n        <Landmarks>381.1</Landmarks>\\n        <Landmarks>201.72</Landmarks>\\n        <Landmarks>448.09</Landmarks>\\n        <Landmarks>205.17</Landmarks>\\n        <Landmarks>415.19</Landmarks>\\n        <Landmarks>191.2</Landmarks>\\n        <Landmarks>415.28</Landmarks>\\n        <Landmarks>201.64</Landmarks>\\n        <Landmarks>391.35</Landmarks>\\n        <Landmarks>196.03</Landmarks>\\n        <Landmarks>403.15</Landmarks>\\n        <Landmarks>191.57</Landmarks>\\n        <Landmarks>426.94</Landmarks>\\n        <Landmarks>194.07</Landmarks>\\n        <Landmarks>438.42</Landmarks>\\n        <Landmarks>197.65</Landmarks>\\n        <LandmarkScore>95.89</LandmarkScore>\\n        <LandmarkCount>105</LandmarkCount>\\n        <Qualities>\\n            <ScoreList>99.92</ScoreList>\\n            <BlurList>99.21</BlurList>\\n            <FnfList>100</FnfList>\\n            <GlassList>100</GlassList>\\n            <IlluList>100</IlluList>\\n            <MaskList>99.53</MaskList>\\n            <NoiseList>99.74</NoiseList>\\n            <PoseList>100</PoseList>\\n        </Qualities>\\n    </Data>\\n</DetectFaceResponse>\",\"errorExample\":\"\"}]","title":"人脸检测定位","summary":"本文介绍人脸检测与五官定位DetectFace的语法及示例。","description":"## 功能描述\n人脸检测与五官定位能力可以检测图片中的人脸并给出每张人脸精准定位和105个关键点信息。输出人脸数量、人脸矩形坐标、人脸姿态、双瞳孔中心坐标、人脸置信度列表等信息，支持人脸遮挡、光照、模糊度、姿态、噪声综合质量评分，支持检测含有多张人脸的照片多种姿态角度判断。\n\n> - 您可以进入[在线咨询](https://www.aliyun.com/core/online-consult?from=aZgW6LJHr2)获取在线人工帮助。\n- 当前能力可在视觉智能开放平台有完整的免费产品体验，您可以单击[立即试用](https://vision.aliyun.com/experience/detail?&tagName=facebody&children=DetectFace)对该能力进行更直观试用以及在线购买。\n- 阿里云视觉智能开放平台视觉AI能力API接入、接口使用或问题咨询等，请通过钉钉群（23109592）加入阿里云视觉智能开放平台咨询群联系我们。\n\n## 应用场景\n人脸关键点检测，是后续识别、分析和特效应用的基础。它为人脸识别、表情分析、疲劳检测、三维人脸重建、人脸美颜、换脸等人脸相关应用提供了人脸精确信息。\n\n- 互动娱乐应用：支持人脸五官及轮廓精准定位，实现动态贴纸、小视频玩法、特效相机等互动娱乐功能。\n- 人脸美颜拍摄：高精度人脸关键点可进行美颜塑形，落地在图片、视频、互动直播等多种美颜场景。\n- 面部定位分析：支持人脸轮廓精准定位和面部关键点分析，落地在智能医美、智能APP等高价值场景。\n\n## 特色优势\n\n- 高精度定位：支持眉毛、眼睛、瞳孔、鼻子、嘴等五官位置的精准定位。\n- 适应能力强：不同照片、人脸尺寸多场景下，适应最大90度侧脸、平面360旋转人脸等情景。\n- 支持多人脸：支持单图检测多个人脸，应对人脸编辑、换脸、姿态矫正等高精度人脸定位场景。\n- 图片质量打分：支持人脸遮挡、光照、模糊度、姿态、噪声综合质量评分。\n- 平台服务稳定：提供在高并发，大流量下的毫秒级识别响应和99.999%的可靠性保障。\n\n## 接入指引\n1. 注册阿里云账号：打开[阿里云官网](https://www.aliyun.com)，在阿里云官网右上角，单击**立即注册**，按照操作提示完成账号注册。\n2. 开通能力：请确保您已开通[人脸人体服务](https://vision.aliyun.com/facebody)，若未开通服务请[立即开通](https://common-buy.aliyun.com/?commodityCode=viapi_facebody_public_cn#/open)。\n> 本能力支持企业或个人认证用户开通。更多实名认证操作信息，请参见[实名认证](https://help.aliyun.com/knowledge_list/37170.html)。\n3. 创建AccessKey：请确保您已[创建AccessKey](~~175144~~)，如果您使用的是子账号AccessKey，您需要给子账号赋予AliyunVIAPIFullAccess权限，具体操作，请参见[RAM授权](~~145025~~)。\n4. 在线调试（可选）：您可以通过[OpenAPI Explorer](https://next.api.aliyun.com/api/facebody/2019-12-30/DetectFace?lang=JAVA&sdkStyle=dara&params=%7B%22ImageURL%22%3A%22http%3A%2F%2Fviapi-test.oss-cn-shanghai.aliyuncs.com%2Fviapi-3.0domepic%2Ffacebody%2FDetectFace%2FDetectFace1.png%22%7D&tab=DEMO)在线调试能力，查看完整的调用示例代码及SDK依赖信息，也可以下载完整的工程。\n5. 开发接入步骤：\n- 在[SDK总览](~~145033~~)中选择您要接入使用的SDK语言。\n- 在对应语言的SDK文档中找到AI类目为人脸人体（facebody）的SDK包进行安装。\n- 参考文档中提供的示例代码进行适当修改后调用。\n\n6. 示例代码：该能力常用语言的示例代码，请参见[人脸检测与五官定位示例代码](~~465559~~)。\n7. 客户端直接调用：该能力常用的客户端调用方式包括以下几种。\n- [Web前端直接调用](~~467779~~)\n- [小程序场景下直接调用](~~467780~~)\n- [Android端直接调用](~~467781~~)\n- [iOS端直接调用](~~467782~~)\n\n## 输入限制\n\n- 图像格式：JPEG、JPG、PNG、BMP。\n- 图像大小：不超过30 MB。\n- 图像分辨率：大于32×32像素，小于8192×8192像素，人脸占比不低于64×64像素。\n- URL地址中不能包含中文字符。\n\n> 当图像分辨率超过最大限制时，请先将图片进行缩放，调整图片大小，具体请参见[图片缩放](~~44688~~)。\n\n## 计费说明\n关于人脸检测与五官定位的计费方式及报价，请参见[计费介绍](~~184049~~)。","requestParamsDescription":" ","responseParamsDescription":"## 示意图\n\n- 原图![](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/file-manage-files/zh-CN/20221108/epcj/DetectFace.png\" width=\"400)\n\n- 105关键点示意图![](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/file-manage-files/zh-CN/20221108/zetr/DetectFace105.png\" width=\"400)\n\n## SDK参考\n阿里云视觉AI人脸人体类目下的人脸检测与五官定位能力推荐使用SDK调用，支持多种编程语言，调用时请选择AI类目为人脸人体（facebody）的SDK包，文件参数通过SDK调用可支持本地文件及任意URL，具体可参见[SDK总览](~~145033~~)。\n\n## 示例代码\n该能力常用语言的示例代码，请参见[人脸检测与五官定位示例代码](~~465559~~)。","extraInfo":"## 错误码\n关于人脸检测与五官定位的错误码，详情请参见[常见错误码](~~146756~~)。\n\n## 开源模型体验\n更多开源免费模型体验及下载，详见魔搭社区：[106点人脸关键点-通用领域-2D](https://www.modelscope.cn/models/damo/cv_mobilenet_face-2d-keypoints_alignment/summary)和[全身关键点检测-通用领域-2D](https://www.modelscope.cn/models/damo/cv_hrnetw48_human-wholebody-keypoint_image/summary)。\n\n## 安全声明\n- 请确保上传的图片或文件来源符合相应的法律法规。\n- 通过体验调试上传的临时文件有效期为1小时，在24小时后会被系统自动清理删除。\n- 平台不存储用户在使用服务过程中涉及的原始人脸图片或文件信息。"}