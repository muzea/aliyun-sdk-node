{"summary":"新增数据湖的元数据表。","path":"/api/metastore/catalogs/databases/tables","methods":["post"],"schemes":["http","https"],"security":[{"AK":[]}],"consumes":["application/json"],"produces":["application/json"],"operationType":"readAndWrite","deprecated":false,"systemTags":{},"parameters":[{"name":"Body","in":"body","style":"json","schema":{"title":"body","description":"HTTP 请求体（HTTP BODY）内容，均采用JSON格式","type":"object","properties":{"CatalogId":{"title":"CatalogId","description":"数据库分类命名空间，默认填写主账号Uid","type":"string","required":false,"example":"1344371"},"DatabaseName":{"title":"DatabaseName","description":"元数据库名称","type":"string","required":false,"example":"database_test"},"TableInput":{"description":"元数据表详细信息","required":false,"$ref":"#/components/schemas/TableInput"}},"required":false}}],"responses":{"200":{"schema":{"title":"Code","description":"返回结果","type":"object","properties":{"Code":{"title":"Code","description":"状态码描述","type":"string","example":"OK"},"Message":{"title":"Message","description":"提示相关错误信息","type":"string","example":"."},"RequestId":{"title":"RequestId","description":"请求ID","type":"string","example":"B7F4B621-E41E-4C84-B97F-42B5380A32BB"},"Success":{"title":"Success","description":"是否成功","type":"boolean","example":"true"}}}},"5XX":{"schema":{"title":"Code","description":"Code","type":"object","properties":{"Code":{"title":"code","description":"code","type":"string"}}}}},"responseDemo":"[{\"type\":\"json\",\"example\":\"{\\n  \\\"Code\\\": \\\"OK\\\",\\n  \\\"Message\\\": \\\".\\\",\\n  \\\"RequestId\\\": \\\"B7F4B621-E41E-4C84-B97F-42B5380A32BB\\\",\\n  \\\"Success\\\": true\\n}\",\"errorExample\":\"\"},{\"type\":\"xml\",\"example\":\"\",\"errorExample\":\"\"}]","title":"新增元数据表","responseParamsDescription":"Code错误码说明  \nInvalidObject：name/partition/column/skewCol 校验不通过  \nAlreadyExists：对应的元数据表已经存在    \nNoSuchObject：对应的元数据库不存在  \nInternalError：其他类型错误，请参考Message提示","extraInfo":"注：表支持的数据格式  \n创建表时用户必须指定数据格式，参数示例如下  \n**avro格式：**  \n table.Parameters: {\"classification\":\"avro\"}  \n table.Sd:  \n \"InputFormat\":\"org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat\"  \n \"OutputFormat\":\"org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat\"  \n \"SerdeInfo\":{\"SerializationLib\":\"org.apache.hadoop.hive.serde2.avro.AvroSerDe\",\"Parameters\":{\"serialization.format\":\"1\"}}  \n  **json格式:**  \n table.Parameters:{\"classification\":\"json\"}  \n table.Sd:  \n \"InputFormat\":\"org.apache.hadoop.mapred.TextInputFormat\"  \n \"OutputFormat\":\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\"  \n \"SerdeInfo\":{\"Parameters\":{\"paths\":\",\"},\"SerializationLib\":\"org.apache.hive.hcatalog.data.JsonSerDe\"}  \n **xml格式**  \n table.Parameters:{\"classification\":\"json\"}  \n \"InputFormat\":\"com.ibm.spss.hive.serde2.xml.XmlInputFormat\"  \n \"OutputFormat\":\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\",  \n \"SerdeInfo\":{\"Parameters\":{\"rowTag\":\"\"},\"SerializationLib\":\"com.ibm.spss.hive.serde2.xml.XmlSerDe\"}  \n **parquet格式**  \n table.Parameters:{\"classification\":\"parquet\"}  \n \"InputFormat\":\"org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat\"  \n \"OutputFormat\":\"org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat\"  \n \"SerdeInfo\":{\"Parameters\":{\"serialization.format\":\"1\"},\"SerializationLib\":\"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\"}  \n **csv格式**  \n table.Parameters:{\"classification\":\"csv\"}  \n \"InputFormat\":\"org.apache.hadoop.mapred.TextInputFormat\",  \n \"OutputFormat\":\"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\",  \n \"SerdeInfo\":{\"Parameters\":{\"separatorChar\":\",\"},\"SerializationLib\":\"org.apache.hadoop.hive.serde2.OpenCSVSerde\"}  \n 注意：separatorChar（分隔符）页面填的,比如“,” 逗号  \n **orc格式**  \n table.Parameters:{\"classification\":\"orc\"}  \n \"InputFormat\":\"org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\",  \n \"OutputFormat\":\"org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat\",  \n \"SerdeInfo\":{\"Parameters\":{},\"SerializationLib\":\"org.apache.hadoop.hive.ql.io.orc.OrcSerde\"}"}